{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = pd.read_csv(\"D:/Institutions.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128543, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['factset_entity_id', 'quarter', 'rquarter', 'ENTITY_PROPER_NAME',\n",
       "       'CUSIP', 'TIC', 'mktcap', 'io_usd', 'nbr_firms', 'io', 'io_dom',\n",
       "       'io_for', 'io_cat1', 'io_cat2', 'io_cat3', 'io_cat4', 'io_cat5',\n",
       "       'io_cat6', 'io_cat7', 'io_indep', 'ibh_5pct', 'ibh_1pct', 'top5',\n",
       "       'herf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many US stocks are in the data set\n",
    "\n",
    "# CUSIP  code for us stocks contains only numbers\n",
    "\n",
    "#num_cusip = []\n",
    "\n",
    "#for i in range(0,len(institutions)):\n",
    "#        num_cusip.append(str.isdigit(str(institutions['CUSIP'][i]))) #I fianlly get it. Append makes a big diff sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8899"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only_US = institutions[num_cusip]\n",
    "\n",
    "#len(only_US['CUSIP'].unique())\n",
    "\n",
    "# 8899 stocks is a lot. Its safe to assume we have institutional data for all US stocks. we are going to use this data set then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232844, 27)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only_US.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = pd.read_csv(\"D:/Financials.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826815, 33)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials.shape\n",
    "\n",
    "# So the financials data is nearly 3.5 times bigger than institutional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FS_PERM_SEC_ID', 'CUSIP', 'TIC', 'EXCOUNTRY', 'PRIMARY_SIC_CODE',\n",
       "       'ZIP_POSTAL_CODE', 'FF_COMPACT', 'FF_MKT_VAL_CURR', 'FF_IS_ADR',\n",
       "       'FF_SECACT', 'DATE', 'FF_COM_SHS_OUT_EPS_DIL', 'FF_RECEIV_ST',\n",
       "       'FF_CURR_RATIO', 'FF_GROSS_MGN', 'FF_NET_MGN', 'FF_ROA', 'FF_ROE',\n",
       "       'FF_ROTC', 'FF_PBK', 'FF_LTD_COM_EQ', 'FF_SALES_PS_GR', 'FF_TAX_RATE',\n",
       "       'FF_ZSCORE', 'FF_PE_DIL', 'FF_PFCF_DIL', 'FF_PSALES_DIL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19980630\n",
       "2    19980930\n",
       "3    19990331\n",
       "4    19990630\n",
       "Name: DATE, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i wonder if it is possible to join financials and institutions data sets on CUSIP and date?\n",
    "\n",
    "financials['DATE'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    200302\n",
       "2    200303\n",
       "3    200304\n",
       "4    200401\n",
       "Name: quarter, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions['quarter'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    06/30/2003\n",
       "2    09/30/2003\n",
       "3    12/31/2003\n",
       "4    03/31/2004\n",
       "Name: rquarter, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions['rquarter'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['month1'] = financials['DATE'].astype(str).str[4]\n",
    "financials['month2'] = financials['DATE'].astype(str).str[5]\n",
    "financials['month'] = financials['month1'] + financials['month2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(707613, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials2 = financials\n",
    "financials2['month'] = financials2['month'].astype(str).astype(int)\n",
    "typical_quarter_end = [3,6,9,12]\n",
    "financials2 = financials2.loc[financials2['month'].isin(typical_quarter_end)]\n",
    "financials2.shape\n",
    "\n",
    "# willing to ignore that 16% of data. Will decide later. With the systems I am trying to build and currently use, Portfolio's can be shuffled only 4 times. Can't make exceptions for some firms. moreover, most big firms follow the typical quarter ending schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61998\n",
       "2    91998\n",
       "3    31999\n",
       "4    61999\n",
       "Name: date_modified, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials['year'] = financials['DATE'].astype(str)\n",
    "financials['year'] = financials.year.str[0:4]\n",
    "financials['month'] = financials['month'].astype(str)\n",
    "financials['date_modified'] = financials['month'] + financials['year']\n",
    "financials['date_modified'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['month'] = institutions['rquarter'].astype(str)\n",
    "institutions['month'] = institutions.rquarter.str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['year'] = institutions['rquarter'].astype(str)\n",
    "institutions['year'] = institutions.rquarter.str[6:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['date_modified'] = institutions['month'] + institutions['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    062003\n",
       "2    092003\n",
       "3    122003\n",
       "4    032004\n",
       "Name: date_modified, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions['date_modified'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming the real keys to be joined on\n",
    "\n",
    "financials['key1'] = financials['date_modified'] + financials['CUSIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    061998FDSA783E7\n",
       "2    091998FDSA783E7\n",
       "3    031999FDSA783E7\n",
       "4    061999FDSA783E7\n",
       "Name: key1, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials['key1'][1:5]\n",
    "\n",
    "# If i remember right, there are some canadian stocks also in the financials set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'OTC', 'NAS', 'NYS', 'TSE', 'ASE', 'TSX', 'LON', 'ASX', 'PHS',\n",
       "       'SWX', 'PSE', 'MEX', 'FRA', 'BUE', 'ETR', 'CAR', 'OSL', 'AMS',\n",
       "       'BSP', 'PAR', 'TAI', 'HKG', 'MIC', 'SES', 'CNQ', 'TKS', 'BOM',\n",
       "       'OME', 'JSE', 'STU', 'GUA', 'MCE', 'WAR', 'MUN', 'MIL', 'TAE',\n",
       "       'JKT', 'HEL', 'SHE', 'CSE', 'SHG', 'BOG', 'BKK', 'COL', 'ATH',\n",
       "       'RUS', 'NGM', 'KRX', 'IST', 'NSA', 'BATS', 'MAU'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials['EXCOUNTRY'].unique()\n",
    "\n",
    "# I just relaized that I have data for 53 countries. What a shame we do not have price data. I can scrape but let me just focus on american stocks for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342757, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_markets = ['NAS', 'NYS', 'BATS']\n",
    "\n",
    "financials_us = financials.loc[financials['EXCOUNTRY'].isin(usa_markets)]\n",
    "financials_us.shape\n",
    "# 342757 rows. Sounds right to me. But did I aslo include U.S. bonds? We will know soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8492"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(financials_us['CUSIP'].unique())\n",
    "\n",
    "# 8492. Seems very reasonable and also in line with what we saw in earlier data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    062003170386106\n",
       "2    092003170386106\n",
       "3    122003170386106\n",
       "4    032004170386106\n",
       "Name: key2, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions['key2'] = institutions['date_modified'] + institutions['CUSIP']\n",
    "\n",
    "institutions['key2'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged = pd.merge(financials_us,\n",
    "                                          institutions,\n",
    "                                          left_on='key1',\n",
    "                                          right_on='key2',\n",
    "                                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342757, 61)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_institutions_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FS_PERM_SEC_ID', 'CUSIP_x', 'TIC_x', 'EXCOUNTRY', 'PRIMARY_SIC_CODE',\n",
       "       'ZIP_POSTAL_CODE', 'FF_COMPACT', 'FF_MKT_VAL_CURR', 'FF_IS_ADR',\n",
       "       'FF_SECACT', 'DATE', 'FF_COM_SHS_OUT_EPS_DIL', 'FF_RECEIV_ST',\n",
       "       'FF_CURR_RATIO', 'FF_GROSS_MGN', 'FF_NET_MGN', 'FF_ROA', 'FF_ROE',\n",
       "       'FF_ROTC', 'FF_PBK', 'FF_LTD_COM_EQ', 'FF_SALES_PS_GR', 'FF_TAX_RATE',\n",
       "       'FF_ZSCORE', 'FF_PE_DIL', 'FF_PFCF_DIL', 'FF_PSALES_DIL', 'month1',\n",
       "       'month2', 'month_x', 'year_x', 'date_modified_x', 'key1', 'final_key1',\n",
       "       'final_key2', 'factset_entity_id', 'quarter', 'rquarter',\n",
       "       'ENTITY_PROPER_NAME', 'CUSIP_y', 'TIC_y', 'mktcap', 'io_usd',\n",
       "       'nbr_firms', 'io', 'io_dom', 'io_for', 'io_cat1', 'io_cat2', 'io_cat3',\n",
       "       'io_cat4', 'io_cat5', 'io_cat6', 'io_cat7', 'io_indep', 'ibh_5pct',\n",
       "       'ibh_1pct', 'top5', 'herf', 'month_y', 'year_y', 'date_modified_y',\n",
       "       'key2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_institutions_merged.columns\n",
    "\n",
    "# I just realized that common name columns are renamed as colname_x and colname_y. Thanks Wes Mckinney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8492"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(financials_institutions_merged['CUSIP_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5190"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(financials_institutions_merged['CUSIP_y'].unique())\n",
    "\n",
    "# I remember that the institution data set starts from 2000. However, the financial data set starts from 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So there are 8492 CUSIP's. That's great. But, for how many stocks do we have atleast 4 values (4 quarters is 1 year)\n",
    "# If a stock hasn't traded for atleast a year, i think its best if I just drop that CUSIP right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_count_df = financials_institutions_merged[['CUSIP_x','FS_PERM_SEC_ID']].groupby(['CUSIP_x']).agg(['count'])\n",
    "CUSIP_count_df.columns = ['count']\n",
    "CUSIP_count_df['CUSIP_stock'] = CUSIP_count_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04463024022609515"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CUSIP_count_df[CUSIP_count_df['count'] < 5])/len(CUSIP_count_df)\n",
    "\n",
    "# I am so relieved to know that barely 5% of stocks in the data traded for less than a year. let me just get a frequency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the monthly price and volume data set\n",
    "\n",
    "price_volume = pd.read_csv(\"D:/Monthly price and volume.csv\", encoding='latin-1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2527070, 23)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>SICCD</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>SHRCLS</th>\n",
       "      <th>TSYMBOL</th>\n",
       "      <th>TRDSTAT</th>\n",
       "      <th>SECSTAT</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>...</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>CFACPR</th>\n",
       "      <th>CFACSHR</th>\n",
       "      <th>vwretd</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>02/28/1990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4920</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>7953</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.008539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>03/30/1990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4920</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>7953</td>\n",
       "      <td>...</td>\n",
       "      <td>10.125</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.024255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>04/30/1990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4920</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>7953</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.028286</td>\n",
       "      <td>-0.028116</td>\n",
       "      <td>-0.026887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>05/31/1990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4920</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>7953</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.750</td>\n",
       "      <td>279.0</td>\n",
       "      <td>-0.012658</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.088934</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.091989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO        date  SHRCD SICCD              COMNAM SHRCLS TSYMBOL TRDSTAT  \\\n",
       "1   10001  02/28/1990   11.0  4920  GREAT FALLS GAS CO    NaN    GFGC       A   \n",
       "2   10001  03/30/1990   11.0  4920  GREAT FALLS GAS CO    NaN    GFGC       A   \n",
       "3   10001  04/30/1990   11.0  4920  GREAT FALLS GAS CO    NaN    GFGC       A   \n",
       "4   10001  05/31/1990   11.0  4920  GREAT FALLS GAS CO    NaN    GFGC       A   \n",
       "\n",
       "  SECSTAT  PERMCO    ...      ASKHI    PRC    VOL        RET  SHROUT  CFACPR  \\\n",
       "1       R    7953    ...     10.000 -9.875  149.0  -0.006289  1022.0     3.0   \n",
       "2       R    7953    ...     10.125 -9.875  127.0   0.012658  1027.0     3.0   \n",
       "3       R    7953    ...     10.000 -9.875  166.0   0.000000  1027.0     3.0   \n",
       "4       R    7953    ...     10.000  9.750  279.0  -0.012658  1027.0     3.0   \n",
       "\n",
       "  CFACSHR    vwretd    ewretd    sprtrn  \n",
       "1     3.0  0.014901  0.015434  0.008539  \n",
       "2     3.0  0.024140  0.021315  0.024255  \n",
       "3     3.0 -0.028286 -0.028116 -0.026887  \n",
       "4     3.0  0.088934  0.045673  0.091989  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_volume[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23694"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSIP_list = price_volume['CUSIP']\n",
    "CUSIP_list = list(set(CUSIP_list))\n",
    "len(CUSIP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23694"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just of curiousity, how many unique PERM_NO are there?\n",
    "\n",
    "PERMNO_list = price_volume['PERMNO']\n",
    "PERMNO_list = list(set(PERMNO_list))\n",
    "len(PERMNO_list)\n",
    "\n",
    "# I know that 1 PERMNO can have multiple CUSIP. yet interestingly, both have same number of uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its interesting that there are nearly 23694 CUSIP's though. \n",
    "\n",
    "# Were there 23,000 stocks since 1990. I don't think so. If there were that many, I have the financials data only for roughly 8000\n",
    "# My guess is that those extra 15000 stocks are OTC, ADR, candian or penny stocks etc. Let me confirm that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_list2 = CUSIP_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26927920'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSIP_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(CUSIP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "9\n",
      "2\n",
      "7\n",
      "9\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in CUSIP_list2:\n",
    "    print(i)\n",
    "    \n",
    "# What's going on here? Didn't expect this. Really sneaky error which I found out further down wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERMNO_list2 = PERMNO_list[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10003, 10005]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERMNO_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10003\n",
      "10005\n"
     ]
    }
   ],
   "source": [
    "for i in PERMNO_list2:\n",
    "    print(i)\n",
    "\n",
    "# Amazing. It works fine with PERMNO though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERMNO       int64\n",
       "date        object\n",
       "SHRCD      float64\n",
       "SICCD       object\n",
       "COMNAM      object\n",
       "SHRCLS      object\n",
       "TSYMBOL     object\n",
       "TRDSTAT     object\n",
       "SECSTAT     object\n",
       "PERMCO       int64\n",
       "CUSIP       object\n",
       "NWPERM     float64\n",
       "BIDLO      float64\n",
       "ASKHI      float64\n",
       "PRC        float64\n",
       "VOL        float64\n",
       "RET         object\n",
       "SHROUT     float64\n",
       "CFACPR     float64\n",
       "CFACSHR    float64\n",
       "vwretd     float64\n",
       "ewretd     float64\n",
       "sprtrn     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_volume.dtypes\n",
    "\n",
    "# And that's why they say to set the type if column is too important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important thing is to convert the entire monthly price volume data set into quarterly paradigm\n",
    "\n",
    "# Before we do that lets play with some columns to ensure I am manipualting them correctly when I do the conversion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most of the columns we only expect positive values.\n",
    "\n",
    "# Broadly, for some of the columns a negative value or zero indicates something. So, how many special situations are there across columns\n",
    "# For more specific details, refer to data dictionary\n",
    "\n",
    "def bad_data(column_name):\n",
    "    nulls = len(price_volume[price_volume[column_name] == None])/len(price_volume)\n",
    "    zeros = len(price_volume[price_volume[column_name] == 0])/len(price_volume)\n",
    "    negatives = len(price_volume[price_volume[column_name] < 0])/len(price_volume)\n",
    "    special_situations = pd.Series([nulls, zeros, negatives])\n",
    "    return special_situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.001427\n",
      "2    0.000000\n",
      "dtype: float64\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.050711\n",
      "dtype: float64\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.069031\n",
      "dtype: float64\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.039084\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-d98b10f0a11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PRC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BIDLO'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RET'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SHROUT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-163-4455813907ec>\u001b[0m in \u001b[0;36mbad_data\u001b[1;34m(column_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnulls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mzeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnegatives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_volume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mspecial_situations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnulls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mspecial_situations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "print(bad_data('VOL'))\n",
    "print(bad_data('ASKHI'))\n",
    "print(bad_data('PRC'))\n",
    "print(bad_data('BIDLO'))\n",
    "print(bad_data('RET'))\n",
    "print(bad_data('SHROUT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_data('SHROUT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasanth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Prasanth\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-7465acbeb7a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindividual_stock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthree_month_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthree_month_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthree_month_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mall_stocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_stocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindividual_stock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    586\u001b[0m                 \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m                     \u001b[0msetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36msetter\u001b[1;34m(item, v)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[1;31m# reset the sliced object if unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mcan_do_equal_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2329\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2330\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2398\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   3733\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3734\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m                 \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, locs, values, check)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \"\"\"\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The most important thing is to convert the entire monthly price volume data set into quarterly paradigm\n",
    "\n",
    "all_stocks = price_volume[1:1] # nice way to set all stocks df the columns of price_volume\n",
    "\n",
    "for i in PERMNO_list:\n",
    "    individual_stock = price_volume[price_volume['PERMNO'] == i]\n",
    "    vol_num = individual_stock.columns.get_loc(\"VOL\")\n",
    "    individual_stock['three_month_vol'] = 1\n",
    "    individual_stock['High'] = individual_stock[]\n",
    "    three_month_num = individual_stock.columns.get_loc(\"three_month_vol\")\n",
    "    for j in range(2,len(individual_stock)):\n",
    "        individual_stock.iloc[j,three_month_num] = individual_stock.iloc[j, vol_num] + individual_stock.iloc[j-1, vol_num] + individual_stock.iloc[j-2, vol_num]\n",
    "        individual_stock.iloc[0, three_month_num] = individual_stock.iloc[0, vol_num]*3\n",
    "        individual_stock.iloc[1, three_month_num] = individual_stock.iloc[1, vol_num]*3\n",
    "    all_stocks = all_stocks.append(individual_stock, ignore_index=True)    \n",
    "    \n",
    "# ignore the warnings below. Its the typical 'a value being set on slice etc.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f = pd.read_csv(\"D:/13F.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f.shape\n",
    "\n",
    "# 6.7 million rows. This data set is much bigger than the previous 2 data sets. But most importantly, it is possible to use columns to join this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FACTSET_ENTITY_ID', 'FSYM_ID', 'REPORT_DATE', 'ADJ_MV',\n",
       "       'REPORTED_HOLDING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8135"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fund13f['FACTSET_ENTITY_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59980"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fund13f['FSYM_ID'].unique())\n",
    "\n",
    "# I thought FSYM_ID is the unique key for stocks. But there aren't 59,980 stocks. May be FACTSET_ENTITY_ID is the unique key for stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    000BJX-E\n",
       "2    000BJX-E\n",
       "3    000BJX-E\n",
       "4    000BJX-E\n",
       "Name: FACTSET_ENTITY_ID, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f['FACTSET_ENTITY_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    B00CQC-S\n",
       "2    B00CQC-S\n",
       "3    B00CQC-S\n",
       "4    B00CQC-S\n",
       "Name: FSYM_ID, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f['FSYM_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    T1N9J9-S-US\n",
       "2    T1N9J9-S-US\n",
       "3    T1N9J9-S-US\n",
       "4    T1N9J9-S-US\n",
       "Name: FS_PERM_SEC_ID, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_institutions_merged['FS_PERM_SEC_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified on WRDS forums. FACTSET_ENTITY_ID is the actual unique key for stocks. Is it referred by a different name in the earlier merged data set\n",
    "\n",
    "stocks_code1 = fund13f['FACTSET_ENTITY_ID']\n",
    "stocks_code2 = financials_institutions_merged['FS_PERM_SEC_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_codes1 = pd.Series(list(set(stocks_code1).intersection(set(stocks_code2))))\n",
    "\n",
    "len(common_codes1)\n",
    "\n",
    "# But there are no common codes. I think the financials_institutions_merged codes have '-US' at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f['New_FSYM_ID'] = fund13f['FSYM_ID'] + '-US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACTSET_ENTITY_ID</th>\n",
       "      <th>FSYM_ID</th>\n",
       "      <th>REPORT_DATE</th>\n",
       "      <th>ADJ_MV</th>\n",
       "      <th>REPORTED_HOLDING</th>\n",
       "      <th>New_FSYM_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>03/31/2005</td>\n",
       "      <td>390040.0</td>\n",
       "      <td>9800</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>06/30/2005</td>\n",
       "      <td>390299.0</td>\n",
       "      <td>9100</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>09/30/2005</td>\n",
       "      <td>417417.0</td>\n",
       "      <td>9100</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>12/31/2005</td>\n",
       "      <td>188225.0</td>\n",
       "      <td>4350</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FACTSET_ENTITY_ID   FSYM_ID REPORT_DATE    ADJ_MV  REPORTED_HOLDING  \\\n",
       "1          000BJX-E  B00CQC-S  03/31/2005  390040.0              9800   \n",
       "2          000BJX-E  B00CQC-S  06/30/2005  390299.0              9100   \n",
       "3          000BJX-E  B00CQC-S  09/30/2005  417417.0              9100   \n",
       "4          000BJX-E  B00CQC-S  12/31/2005  188225.0              4350   \n",
       "\n",
       "   New_FSYM_ID  \n",
       "1  B00CQC-S-US  \n",
       "2  B00CQC-S-US  \n",
       "3  B00CQC-S-US  \n",
       "4  B00CQC-S-US  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7539"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f_stock_codes = fund13f2['New_FSYM_ID']\n",
    "earlier_merged_stock_codes = financials_institutions_merged['FS_PERM_SEC_ID']\n",
    "\n",
    "common_codes = pd.Series(list(set(fund13f_stock_codes).intersection(set(earlier_merged_stock_codes))))\n",
    "len(common_codes)\n",
    "\n",
    "# yup. Adding 'US' did the trick\n",
    "\n",
    "# Read the research papers written by Professor Mateos who developed the institutional data set. It appears he is focused on corporate finance related metrics rather qunatitative asset management (or predicting stock market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we can use the 13F data set, the question is how do I calculate 'how good a fund is?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                Stock Market Technical and Fundamental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  Loading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Data Wrangling and joining data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Loading in the institutional data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Please check out the google drive link for Data dictionary and other project maaterials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = pd.read_csv(\"D:/Institutions.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many US stocks are in the data set\n",
    "\n",
    "# CUSIP  code for us stocks contains only numbers\n",
    "\n",
    "#num_cusip = []\n",
    "\n",
    "#for i in range(0,len(institutions)):\n",
    "#        num_cusip.append(str.isdigit(str(institutions['CUSIP'][i]))) #I fianlly get it. Append makes a big diff sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only_US = institutions[num_cusip]\n",
    "\n",
    "#len(only_US['CUSIP'].unique())\n",
    "\n",
    "# 8899 stocks is a lot. Its safe to assume we have institutional data for all US stocks. we are going to use this data set then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only_US.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Loading in the financials data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = pd.read_csv(\"D:/Financials.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials.shape\n",
    "\n",
    "# So the financials data is nearly 3.5 times bigger than institutional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i wonder if it is possible to join financials and institutions data sets on CUSIP and date?\n",
    "\n",
    "financials['DATE'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['quarter'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['rquarter'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['month1'] = financials['DATE'].astype(str).str[4]\n",
    "financials['month2'] = financials['DATE'].astype(str).str[5]\n",
    "financials['month'] = financials['month1'] + financials['month2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials2 = financials\n",
    "financials2['month'] = financials2['month'].astype(str).astype(int)\n",
    "typical_quarter_end = [3,6,9,12]\n",
    "financials2 = financials2.loc[financials2['month'].isin(typical_quarter_end)]\n",
    "financials2.shape\n",
    "\n",
    "# willing to ignore that 16% of data. Will decide later. With the systems I am trying to build and currently use, Portfolio's can be shuffled only 4 times. Can't make exceptions for some firms. moreover, most big firms follow the typical quarter ending schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['year'] = financials['DATE'].astype(str)\n",
    "financials['year'] = financials.year.str[0:4]\n",
    "financials['month'] = financials['month'].astype(str)\n",
    "financials['date_modified'] = financials['month'] + financials['year']\n",
    "financials['date_modified'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['month'] = institutions['rquarter'].astype(str)\n",
    "institutions['month'] = institutions.rquarter.str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['year'] = institutions['rquarter'].astype(str)\n",
    "institutions['year'] = institutions.rquarter.str[6:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['date_modified'] = institutions['month'] + institutions['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['date_modified'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming the real keys to be joined on\n",
    "\n",
    "financials['key1'] = financials['date_modified'] + financials['CUSIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['key1'][1:5]\n",
    "\n",
    "# If i remember right, there are some canadian stocks also in the financials set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['EXCOUNTRY'].unique()\n",
    "\n",
    "# I just relaized that I have data for 53 countries. What a shame we do not have price data. I can scrape but let me just focus on american stocks for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_markets = ['NAS', 'NYS', 'BATS']\n",
    "\n",
    "financials_us = financials.loc[financials['EXCOUNTRY'].isin(usa_markets)]\n",
    "financials_us.shape\n",
    "\n",
    "# 342757 rows. Sounds right to me. But did I aslo include U.S. bonds? We will know soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financials_us['CUSIP'].unique())\n",
    "\n",
    "# 8492. Seems very reasonable and also in line with what we saw in earlier data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions['key2'] = institutions['date_modified'] + institutions['CUSIP']\n",
    "\n",
    "institutions['key2'][1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Joining the financials and institutions data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged = pd.merge(financials_us,\n",
    "                                          institutions,\n",
    "                                          left_on='key1',\n",
    "                                          right_on='key2',\n",
    "                                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged.columns\n",
    "\n",
    "# I just realized that common name columns are renamed as colname_x and colname_y. Thanks Wes Mckinney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financials_institutions_merged['CUSIP_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged['CUSIP_x'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financials_institutions_merged['CUSIP_y'].unique())\n",
    "\n",
    "# I remember that the institution data set starts from 2000. However, the financial data set starts from 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So there are 8492 CUSIP's. That's great. But, for how many stocks do we have atleast 4 values (4 quarters is 1 year)\n",
    "# If a stock hasn't traded for atleast a year, i think its best if I just drop that CUSIP right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_count_df = financials_institutions_merged[['CUSIP_x','FS_PERM_SEC_ID']].groupby(['CUSIP_x']).agg(['count'])\n",
    "CUSIP_count_df.columns = ['count']\n",
    "CUSIP_count_df['CUSIP_stock'] = CUSIP_count_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CUSIP_count_df[CUSIP_count_df['count'] < 5])/len(CUSIP_count_df)\n",
    "\n",
    "# I am so relieved to know that barely 5% of stocks in the data traded for less than a year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Loading in the price and volume data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the monthly price and volume data set\n",
    "\n",
    "price_volume = pd.read_csv(\"D:/Monthly price and volume.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_list = price_volume['CUSIP']\n",
    "CUSIP_list = list(set(CUSIP_list))\n",
    "len(CUSIP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just of curiousity, how many unique PERM_NO are there?\n",
    "\n",
    "PERMNO_list = price_volume['PERMNO']\n",
    "PERMNO_list = list(set(PERMNO_list))\n",
    "len(PERMNO_list)\n",
    "\n",
    "# I know that 1 PERMNO can have multiple CUSIP. yet interestingly, both have same number of uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its interesting that there are nearly 23694 CUSIP's though. \n",
    "\n",
    "# Were there 23,000 stocks since 1990. I don't think so. If there were that many, I have the financials data only for roughly 8000\n",
    "# My guess is that those extra 15000 stocks are OTC, ADR, candian or penny stocks etc. Let me confirm that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume.dtypes\n",
    "\n",
    "# And that's why they say to set the type if column is too important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important thing is to convert the entire monthly price volume data set into quarterly paradigm\n",
    "# I am going to explore this data set deeply right now and not later because I really need to make sure values in original columns make sense before deriving other columns from old ones\n",
    "# lets play with some columns to ensure I am manipualting them correctly when I do the conversion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed some values in numeric columns are strings. Impossible. I am just going to set them as NULL \n",
    "#I don't have the time to go through some special codes that occur once in a century\n",
    "\n",
    "price_volume2 = price_volume[['VOL', 'ASKHI', 'PRC', 'BIDLO', 'RET', 'SHROUT', 'CFACPR', 'CFACSHR', 'vwretd', 'ewretd', 'sprtrn']]\n",
    "no_strings = price_volume2.apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# quick note: its important that we don't run all the above blocks of code to successfully complete the above step\n",
    "# I have a 4gb RAM and I get memory error if run the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume = price_volume.drop(['VOL', 'ASKHI', 'PRC'], axis=1)\n",
    "price_volume = price_volume.drop(['BIDLO'], axis=1)\n",
    "price_volume = price_volume.drop(['RET', 'SHROUT'], axis=1)\n",
    "price_volume = price_volume.drop(['CFACPR', 'CFACSHR', 'vwretd', 'ewretd', 'sprtrn'], axis=1)\n",
    "xcv = price_volume\n",
    "price_volume = pd.concat([xcv, no_strings], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we do anything else, why don't we cut this data set to just the CUSIP codes for which we have financial data\n",
    "\n",
    "CUSIPs_under_consideration = financials_institutions_merged['CUSIP_x'].unique()\n",
    "sdf = price_volume[price_volume['CUSIP'].isin(CUSIPs_under_consideration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[1:5]\n",
    "\n",
    "# no match between the CUSIP codes? wth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume['CUSIP'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIPs_under_consideration[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIPs_under_consideration[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The situation is clear. CUSIP's in price&volume are 8 digits. In the earlier merged file, they are 9 digits. What is happening?\n",
    "\n",
    "# The best stock data base huh? No proper keys to join tables!\n",
    "\n",
    "# Based on google search, it appears that i need to ignore the last digit of the 9 digit CUSIP\n",
    "\n",
    "CUSIPs_under_consideration = pd.Series(CUSIPs_under_consideration)\n",
    "CUSIPs_under_consideration = CUSIPs_under_consideration.str[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume = price_volume[price_volume['CUSIP'].isin(CUSIPs_under_consideration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume[1:5]\n",
    "\n",
    "# it works!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume.shape\n",
    "\n",
    "# almost 50% of the data is cut after selecting only certain CUSIP codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most of the columns we only expect positive values.\n",
    "\n",
    "# Broadly, for some of the columns a negative value or zero indicates something. So, how many special situations are there across columns\n",
    "# For more specific details, refer to data dictionary\n",
    "\n",
    "def bad_data(column_name):\n",
    "    nulls = len(price_volume[price_volume[column_name].isnull()])*100/len(price_volume)\n",
    "    zeros = len(price_volume[price_volume[column_name].astype(float) == 0])*100/len(price_volume)\n",
    "    negatives = len(price_volume[price_volume[column_name].astype(float) < 0])*100/len(price_volume)\n",
    "    special_situations = pd.Series([nulls, zeros, negatives])\n",
    "    return special_situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.018213\n",
      "2    0.000000\n",
      "dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "dtype: float64\n",
      "0     0.000000\n",
      "1     1.622451\n",
      "2    45.337307\n",
      "dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "dtype: float64\n",
      "0    0.000000\n",
      "1    0.523423\n",
      "2    0.000000\n",
      "dtype: float64\n",
      "0    0.000000\n",
      "1    0.523423\n",
      "2    0.000000\n",
      "dtype: float64\n",
      "0     0.000000\n",
      "1     0.000000\n",
      "2    35.445888\n",
      "dtype: float64\n",
      "0     0.000000\n",
      "1     0.000000\n",
      "2    38.205486\n",
      "dtype: float64\n",
      "0     0.000000\n",
      "1     0.000000\n",
      "2    36.928567\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(bad_data('VOL'))\n",
    "print(bad_data('ASKHI'))\n",
    "print(bad_data('PRC'))\n",
    "print(bad_data('BIDLO'))\n",
    "print(bad_data('RET'))\n",
    "print(bad_data('SHROUT'))\n",
    "print(bad_data('CFACPR'))\n",
    "print(bad_data('CFACSHR'))\n",
    "print(bad_data('vwretd'))\n",
    "print(bad_data('ewretd'))\n",
    "print(bad_data('sprtrn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only few negatives for most of the columns. Let me make them positive. I checked the data dictionary to make sure this makes sense\n",
    "\n",
    "price_volume['BIDLO'] = abs(price_volume['BIDLO'])\n",
    "price_volume['VOL'] = abs(price_volume['VOL'])\n",
    "price_volume['ASKHI'] = abs(price_volume['ASKHI'])\n",
    "price_volume['PRC'] = abs(price_volume['PRC'])\n",
    "price_volume['SHROUT'] = abs(price_volume['SHROUT'])\n",
    "price_volume['CFACPR'] = abs(price_volume['CFACPR'])\n",
    "price_volume['CFACSHR'] = abs(price_volume['CFACSHR'])\n",
    "\n",
    "# Oh god. Here we go again. Those copy of slice useless warnings. I don't know why the error is displayed only some times\n",
    "# Don't worry about the warnings anyway\n",
    "\n",
    "# I also noticed something else. SP500 increases daily more than 60% of days\n",
    "# May be all I need to do is buy bullish binary options on NADEX everyday and call of this project. lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what are going to about the nulls though?\n",
    "\n",
    "# Lets see how bad the null value problem is for each column\n",
    "\n",
    "print(len(price_volume))\n",
    "\n",
    "price_volume2 = price_volume\n",
    "price_volume2 = price_volume[price_volume[['VOL', 'ASKHI', 'PRC', 'BIDLO', 'RET', 'SHROUT', 'CFACPR', 'CFACSHR', 'vwretd', 'ewretd', 'sprtrn']].isnull().any(axis=1)]\n",
    "print(len(price_volume2))\n",
    "\n",
    "# It's just 3% by no. of rows. \n",
    "# But its extremely important to look at what % of CUSIP codes we are going to lose because I need to delete all the rows beloning to the CUSIP to ensure there are no missing data for a particular CUSIP (stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(price_volume['CUSIP'].unique()))\n",
    "print(len(price_volume2['CUSIP'].unique()))\n",
    "\n",
    "# so basically, 7472 stocks had a null value at some point in time. Can't delete 7472 stocks obviously\n",
    "# Need to think about this carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to look at the distribution of nulls. For example, are 50 stocks mostly responsible for causing the null problem?\n",
    "\n",
    "null_CUSIP_count = pd.DataFrame(price_volume2.groupby(['CUSIP'])['PERMNO'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_CUSIP_count['PERMNO'].describe()\n",
    "\n",
    "# What is clear is that this a null problem that is spread across many stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(null_CUSIP_count[null_CUSIP_count['PERMNO'] > 3])\n",
    "\n",
    "# But only 308 stocks have 4 or more null values. Why don't we just get rid of these 308 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_remove = pd.Series(null_CUSIP_count[null_CUSIP_count['PERMNO'] > 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_remove[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_volume = price_volume[~price_volume['CUSIP'].isin(CUSIP_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why don't we try impute now? Have to risk it. No option. Its only for less than 3 values anyway\n",
    "\n",
    "price_volume = price_volume.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we are done yet. The nice people at WRDS have used special numeric codes to denote certain special events\n",
    "\n",
    "# for example if ret contains -66 or -77, those values are not really -66 or -77. They are referring to some special situation\n",
    "\n",
    "# I am going to check some numeric columns now to ensure that there are no crazy values. \n",
    "\n",
    "# I need to do something specifically about the zeros. Of course I am referring to the data dictionary and making sure the transformations I am about to do make sense\n",
    "\n",
    "price_volume2 = price_volume[price_volume['VOL'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7992\n",
      "1180498\n"
     ]
    }
   ],
   "source": [
    "print(len(price_volume['CUSIP'].unique()))\n",
    "print(len(price_volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3137\n",
      "115606\n"
     ]
    }
   ],
   "source": [
    "CUSIP_low_vol = price_volume2['CUSIP'].unique()\n",
    "print(len(CUSIP_low_vol))\n",
    "print(len(price_volume2))\n",
    "\n",
    "# So just 30 rows per CUSIP on average for some CUSIP's. 30 months of data. also, so low volume. i don't want to deal with such data\n",
    "\n",
    "# These are problem CUSIP's. Let me remove them\n",
    "\n",
    "price_volume3 = price_volume[~price_volume['CUSIP'].isin(CUSIP_low_vol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RET = price_volume3.columns.get_loc(\"RET\")\n",
    "\n",
    "RET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_RET = price_volume3['RET'].median()\n",
    "\n",
    "for i in range(0,len(price_volume3)):\n",
    "    if price_volume3.iloc[i,RET] == -66 | -77:\n",
    "        price_volume3.iloc[i,RET] = median_RET\n",
    "        \n",
    "# because -66 and -77 are actually special codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_data('VOL'))\n",
    "print(bad_data('ASKHI'))\n",
    "print(bad_data('PRC'))\n",
    "print(bad_data('BIDLO'))\n",
    "print(bad_data('RET'))\n",
    "print(bad_data('SHROUT'))\n",
    "print(bad_data('CFACPR'))\n",
    "print(bad_data('CFACSHR'))\n",
    "print(bad_data('vwretd'))\n",
    "print(bad_data('ewretd'))\n",
    "print(bad_data('sprtrn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasanth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Prasanth\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# The most important thing is to convert the entire monthly price volume data set into quarterly paradigm\n",
    "\n",
    "all_stocks = price_volume3[1:1] # nice way to set all stocks df the columns of price_volume\n",
    "\n",
    "for i in PERMNO_list[1:10]:\n",
    "    individual_stock = price_volume3[price_volume3['PERMNO'] == i]\n",
    "    \n",
    "    vol_num = individual_stock.columns.get_loc(\"VOL\")\n",
    "    high_num = individual_stock.columns.get_loc(\"ASKHI\")\n",
    "    low_num = individual_stock.columns.get_loc(\"BIDLO\")\n",
    "    RET_num = individual_stock.columns.get_loc(\"RET\")\n",
    "    vwretd_num = individual_stock.columns.get_loc(\"vwretd\")\n",
    "    ewretd_num = individual_stock.columns.get_loc(\"ewretd\")\n",
    "    sprtrn_num = individual_stock.columns.get_loc(\"sprtrn\")\n",
    "    \n",
    "    individual_stock['three_month_vol'] = None\n",
    "    individual_stock['three_month_high'] = None\n",
    "    individual_stock['three_month_low'] = None\n",
    "    individual_stock['three_month_RET'] = None\n",
    "    individual_stock['three_month_vwretd'] = None\n",
    "    individual_stock['three_month_ewretd'] = None\n",
    "    individual_stock['three_month_sprtrn'] = None\n",
    "    \n",
    "    three_month_vol = individual_stock.columns.get_loc(\"three_month_vol\")\n",
    "    three_month_high = individual_stock.columns.get_loc(\"three_month_high\")\n",
    "    three_month_low = individual_stock.columns.get_loc(\"three_month_low\")\n",
    "    three_month_RET = individual_stock.columns.get_loc(\"three_month_RET\")\n",
    "    three_month_vwretd = individual_stock.columns.get_loc(\"three_month_vwretd\")\n",
    "    three_month_ewretd = individual_stock.columns.get_loc(\"three_month_ewretd\")\n",
    "    three_month_sprtrn = individual_stock.columns.get_loc(\"three_month_sprtrn\")\n",
    "    \n",
    "    individual_stock.iloc[0,three_month_vol] = individual_stock.iloc[0, vol_num]*3\n",
    "    individual_stock.iloc[1,three_month_vol] = individual_stock.iloc[1, vol_num]*3\n",
    "    individual_stock.iloc[0,three_month_high] = individual_stock.iloc[0, high_num]*3\n",
    "    individual_stock.iloc[1,three_month_high] = individual_stock.iloc[1, high_num]*3\n",
    "    individual_stock.iloc[0,three_month_low] = individual_stock.iloc[0, low_num]*3\n",
    "    individual_stock.iloc[1,three_month_low] = individual_stock.iloc[1, low_num]*3\n",
    "    individual_stock.iloc[0,three_month_RET] = individual_stock.iloc[0, RET_num]*3\n",
    "    individual_stock.iloc[1,three_month_RET] = individual_stock.iloc[1, RET_num]*3\n",
    "    individual_stock.iloc[0,three_month_vwretd] = individual_stock.iloc[0, vwretd_num]*3\n",
    "    individual_stock.iloc[1,three_month_vwretd] = individual_stock.iloc[1, vwretd_num]*3\n",
    "    individual_stock.iloc[0,three_month_ewretd] = individual_stock.iloc[0, ewretd_num]*3\n",
    "    individual_stock.iloc[1,three_month_ewretd] = individual_stock.iloc[1, ewretd_num]*3\n",
    "    individual_stock.iloc[0,three_month_sprtrn] = individual_stock.iloc[0, sprtrn_num]*3\n",
    "    individual_stock.iloc[1,three_month_sprtrn] = individual_stock.iloc[1, sprtrn_num]*3\n",
    "    \n",
    "    \n",
    "    for j in range(2,len(individual_stock)):\n",
    "        individual_stock.iloc[j,three_month_vol] = individual_stock.iloc[j, vol_num] + individual_stock.iloc[j-1, vol_num] + individual_stock.iloc[j-2, vol_num]\n",
    "        individual_stock.iloc[j,three_month_high] = max(individual_stock.iloc[j, high_num], individual_stock.iloc[j-1, high_num], individual_stock.iloc[j-2, high_num])\n",
    "        individual_stock.iloc[j,three_month_low] = min(individual_stock.iloc[j, low_num], individual_stock.iloc[j-1, low_num], individual_stock.iloc[j-2, low_num])\n",
    "        individual_stock.iloc[j,three_month_RET] = (1 + individual_stock.iloc[j,RET_num])(1 + individual_stock.iloc[j-1,RET_num])(1 + individual_stock.iloc[j-2,RET_num])\n",
    "        individual_stock.iloc[j,three_month_vwretd] = (1 + individual_stock.iloc[j,vwretd_num])(1 + individual_stock.iloc[j-1,vwretd_num])(1 + individual_stock.iloc[j-2,vwretd_num])\n",
    "        individual_stock.iloc[j,three_month_vwretd] = (1 + individual_stock.iloc[j,ewretd_num])(1 + individual_stock.iloc[j-1,ewretd_num])(1 + individual_stock.iloc[j-2,ewretd_num])\n",
    "        individual_stock.iloc[j,three_month_sprtrn] = (1 + individual_stock.iloc[j,sprtrn_num])(1 + individual_stock.iloc[j-1,sprtrn_num])(1 + individual_stock.iloc[j-2,sprtrn_num])\n",
    "        \n",
    "        \n",
    "    all_stocks = all_stocks.append(individual_stock, ignore_index=True)    \n",
    "    \n",
    "# ignore the warnings below. Its the typical 'a value being set on slice etc.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>CFACPR</th>\n",
       "      <th>CFACSHR</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>NWPERM</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>PRC</th>\n",
       "      <th>...</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>SICCD</th>\n",
       "      <th>TRDSTAT</th>\n",
       "      <th>TSYMBOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>date</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>three_month_vol</th>\n",
       "      <th>vwretd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.000</td>\n",
       "      <td>21.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>24.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13596.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>9407.0</td>\n",
       "      <td>02/28/1990</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>28221.0</td>\n",
       "      <td>0.014901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.250</td>\n",
       "      <td>22.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>23.75</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>11441.0</td>\n",
       "      <td>03/30/1990</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>0.024140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.000</td>\n",
       "      <td>22.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>22.75</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>04/30/1990</td>\n",
       "      <td>-0.028116</td>\n",
       "      <td>-0.026887</td>\n",
       "      <td>27757.0</td>\n",
       "      <td>-0.028286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.000</td>\n",
       "      <td>22.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>24.25</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>13678.0</td>\n",
       "      <td>05/31/1990</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.091989</td>\n",
       "      <td>32028.0</td>\n",
       "      <td>0.088934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.500</td>\n",
       "      <td>23.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>24.75</td>\n",
       "      <td>...</td>\n",
       "      <td>13593.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>10995.0</td>\n",
       "      <td>06/29/1990</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>31582.0</td>\n",
       "      <td>-0.004196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.125</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>23.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13593.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>8946.0</td>\n",
       "      <td>07/31/1990</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>-0.005223</td>\n",
       "      <td>33619.0</td>\n",
       "      <td>-0.009403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.750</td>\n",
       "      <td>16.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>17.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13593.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>7365.0</td>\n",
       "      <td>08/31/1990</td>\n",
       "      <td>-0.108920</td>\n",
       "      <td>-0.094314</td>\n",
       "      <td>27306.0</td>\n",
       "      <td>-0.091905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.000</td>\n",
       "      <td>15.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>15.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13593.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>09/28/1990</td>\n",
       "      <td>-0.080468</td>\n",
       "      <td>-0.051184</td>\n",
       "      <td>22602.0</td>\n",
       "      <td>-0.053843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.500</td>\n",
       "      <td>10.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FIGGIE INTERNATIONAL INC DEL</td>\n",
       "      <td>81002230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>10016</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13593.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>15200.0</td>\n",
       "      <td>10/31/1990</td>\n",
       "      <td>-0.057155</td>\n",
       "      <td>-0.006698</td>\n",
       "      <td>28856.0</td>\n",
       "      <td>-0.012504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ASKHI  BIDLO  CFACPR  CFACSHR                        COMNAM     CUSIP  \\\n",
       "1  24.000  21.75     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "2  24.250  22.75     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "3  24.000  22.75     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "4  25.000  22.75     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "5  25.500  23.75     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "6  25.125  23.00     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "7  23.750  16.50     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "8  18.000  15.50     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "9  15.500  10.50     1.0      1.0  FIGGIE INTERNATIONAL INC DEL  81002230   \n",
       "\n",
       "   NWPERM  PERMCO  PERMNO    PRC    ...      SHROUT SICCD  TRDSTAT TSYMBOL  \\\n",
       "1     0.0    1728   10016  24.00    ...     13596.0  3560        A   FIGIA   \n",
       "2     0.0    1728   10016  23.75    ...     13590.0  3560        A   FIGIA   \n",
       "3     0.0    1728   10016  22.75    ...     13590.0  3560        A   FIGIA   \n",
       "4     0.0    1728   10016  24.25    ...     13590.0  3560        A   FIGIA   \n",
       "5     0.0    1728   10016  24.75    ...     13593.0  3560        A   FIGIA   \n",
       "6     0.0    1728   10016  23.00    ...     13593.0  3560        A   FIGIA   \n",
       "7     0.0    1728   10016  17.50    ...     13593.0  3560        A   FIGIA   \n",
       "8     0.0    1728   10016  15.50    ...     13593.0  3560        A   FIGIA   \n",
       "9     0.0    1728   10016  12.00    ...     13593.0  3560        A   FIGIA   \n",
       "\n",
       "       VOL        date    ewretd    sprtrn  three_month_vol    vwretd  \n",
       "1   9407.0  02/28/1990  0.015434  0.008539          28221.0  0.014901  \n",
       "2  11441.0  03/30/1990  0.021315  0.024255          25140.0  0.024140  \n",
       "3   6909.0  04/30/1990 -0.028116 -0.026887          27757.0 -0.028286  \n",
       "4  13678.0  05/31/1990  0.045673  0.091989          32028.0  0.088934  \n",
       "5  10995.0  06/29/1990  0.005359 -0.008886          31582.0 -0.004196  \n",
       "6   8946.0  07/31/1990 -0.025731 -0.005223          33619.0 -0.009403  \n",
       "7   7365.0  08/31/1990 -0.108920 -0.094314          27306.0 -0.091905  \n",
       "8   6291.0  09/28/1990 -0.080468 -0.051184          22602.0 -0.053843  \n",
       "9  15200.0  10/31/1990 -0.057155 -0.006698          28856.0 -0.012504  \n",
       "\n",
       "[9 rows x 24 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stocks[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged['CUSIP_cut'] = financials_institutions_merged['CUSIP_x'].str[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_pricevolume =  pd.merge(financials_institutions_merged,\n",
    "                                                all_stocks,\n",
    "                                                left_on='CUSIP_cut',\n",
    "                                                right_on='CUSIP',\n",
    "                                                how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FS_PERM_SEC_ID</th>\n",
       "      <th>CUSIP_x</th>\n",
       "      <th>TIC_x</th>\n",
       "      <th>EXCOUNTRY</th>\n",
       "      <th>PRIMARY_SIC_CODE</th>\n",
       "      <th>ZIP_POSTAL_CODE</th>\n",
       "      <th>FF_COMPACT</th>\n",
       "      <th>FF_MKT_VAL_CURR</th>\n",
       "      <th>FF_IS_ADR</th>\n",
       "      <th>FF_SECACT</th>\n",
       "      <th>...</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>SICCD</th>\n",
       "      <th>TRDSTAT</th>\n",
       "      <th>TSYMBOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>date</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>three_month_vol</th>\n",
       "      <th>vwretd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G0Z82X-S-US</td>\n",
       "      <td>810022301</td>\n",
       "      <td>SCTT.XX1</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>43041</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13596.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>9407.0</td>\n",
       "      <td>02/28/1990</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>28221.0</td>\n",
       "      <td>0.014901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G0Z82X-S-US</td>\n",
       "      <td>810022301</td>\n",
       "      <td>SCTT.XX1</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>43041</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>11441.0</td>\n",
       "      <td>03/30/1990</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>25140.0</td>\n",
       "      <td>0.024140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G0Z82X-S-US</td>\n",
       "      <td>810022301</td>\n",
       "      <td>SCTT.XX1</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>43041</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>A</td>\n",
       "      <td>FIGIA</td>\n",
       "      <td>6909.0</td>\n",
       "      <td>04/30/1990</td>\n",
       "      <td>-0.028116</td>\n",
       "      <td>-0.026887</td>\n",
       "      <td>27757.0</td>\n",
       "      <td>-0.028286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FS_PERM_SEC_ID    CUSIP_x     TIC_x EXCOUNTRY  PRIMARY_SIC_CODE  \\\n",
       "1    G0Z82X-S-US  810022301  SCTT.XX1       NAS            2874.0   \n",
       "2    G0Z82X-S-US  810022301  SCTT.XX1       NAS            2874.0   \n",
       "3    G0Z82X-S-US  810022301  SCTT.XX1       NAS            2874.0   \n",
       "\n",
       "  ZIP_POSTAL_CODE  FF_COMPACT  FF_MKT_VAL_CURR  FF_IS_ADR  FF_SECACT  \\\n",
       "1           43041           0              NaN          0          0   \n",
       "2           43041           0              NaN          0          0   \n",
       "3           43041           0              NaN          0          0   \n",
       "\n",
       "     ...      SHROUT  SICCD  TRDSTAT  TSYMBOL      VOL        date    ewretd  \\\n",
       "1    ...     13596.0   3560        A    FIGIA   9407.0  02/28/1990  0.015434   \n",
       "2    ...     13590.0   3560        A    FIGIA  11441.0  03/30/1990  0.021315   \n",
       "3    ...     13590.0   3560        A    FIGIA   6909.0  04/30/1990 -0.028116   \n",
       "\n",
       "     sprtrn  three_month_vol    vwretd  \n",
       "1  0.008539          28221.0  0.014901  \n",
       "2  0.024255          25140.0  0.024140  \n",
       "3 -0.026887          27757.0 -0.028286  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_institutions_pricevolume[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loading in the 13F data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f = pd.read_csv(\"D:/13F.csv\", encoding='latin-1', nrows = 6000000)\n",
    "\n",
    "# its really mysterious. When I use nrows arguement, its able to read in 6,000,000 rows in less than 30 seconds\n",
    "# However, when I do just read_csv, my pc's getting stuck. I know that there are 6.7 million rows in this file anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f.shape\n",
    "\n",
    "# 6.7 million rows. This data set is much bigger than the previous 2 data sets. But most importantly, it is possible to use columns to join this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FACTSET_ENTITY_ID', 'FSYM_ID', 'REPORT_DATE', 'ADJ_MV',\n",
       "       'REPORTED_HOLDING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fund13f['FACTSET_ENTITY_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fund13f['FSYM_ID'].unique())\n",
    "\n",
    "# I thought FSYM_ID is the unique key for stocks. But there aren't 59,980 stocks. May be FACTSET_ENTITY_ID is the unique key for stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f['FACTSET_ENTITY_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f['FSYM_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_institutions_merged['FS_PERM_SEC_ID'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified on WRDS forums. FACTSET_ENTITY_ID is the actual unique key for stocks. Is it referred by a different name in the earlier merged data set\n",
    "\n",
    "stocks_code1 = fund13f['FACTSET_ENTITY_ID']\n",
    "stocks_code2 = financials_institutions_merged['FS_PERM_SEC_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_codes1 = pd.Series(list(set(stocks_code1).intersection(set(stocks_code2))))\n",
    "\n",
    "len(common_codes1)\n",
    "\n",
    "# But there are no common codes. I think the financials_institutions_merged codes have '-US' at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f['New_FSYM_ID'] = fund13f['FSYM_ID'] + '-US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f_stock_codes = fund13f2['New_FSYM_ID']\n",
    "earlier_merged_stock_codes = financials_institutions_merged['FS_PERM_SEC_ID']\n",
    "\n",
    "common_codes = pd.Series(list(set(fund13f_stock_codes).intersection(set(earlier_merged_stock_codes))))\n",
    "len(common_codes)\n",
    "\n",
    "# yup. Adding 'US' did the trick\n",
    "\n",
    "# Read the research papers written by Professor Mateos who developed the institutional data set. It appears he is focused on corporate finance related metrics rather qunatitative asset management (or predicting stock market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we can use the 13F data set, the question is how do I calculate 'how good a fund is?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FACTSET_ENTITY_ID', 'FSYM_ID', 'REPORT_DATE', 'ADJ_MV',\n",
       "       'REPORTED_HOLDING', 'New_FSYM_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FACTSET_ENTITY_ID        0\n",
       "FSYM_ID                  0\n",
       "REPORT_DATE              0\n",
       "ADJ_MV               45143\n",
       "REPORTED_HOLDING         0\n",
       "New_FSYM_ID              0\n",
       "date_combo               0\n",
       "to_be_joined             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.isnull().sum()\n",
    "\n",
    "# Great the most useful column has 45143 nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_index = fund13f[fund13f['ADJ_MV'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACTSET_ENTITY_ID</th>\n",
       "      <th>FSYM_ID</th>\n",
       "      <th>REPORT_DATE</th>\n",
       "      <th>ADJ_MV</th>\n",
       "      <th>REPORTED_HOLDING</th>\n",
       "      <th>New_FSYM_ID</th>\n",
       "      <th>date_combo</th>\n",
       "      <th>to_be_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>CSTD7Y-S</td>\n",
       "      <td>03/31/2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46400</td>\n",
       "      <td>CSTD7Y-S-US</td>\n",
       "      <td>20020331</td>\n",
       "      <td>03/31/2002CSTD7Y-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>CSTD7Y-S</td>\n",
       "      <td>06/30/2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46400</td>\n",
       "      <td>CSTD7Y-S-US</td>\n",
       "      <td>20020630</td>\n",
       "      <td>06/30/2002CSTD7Y-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>CSTD7Y-S</td>\n",
       "      <td>09/30/2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46400</td>\n",
       "      <td>CSTD7Y-S-US</td>\n",
       "      <td>20020930</td>\n",
       "      <td>09/30/2002CSTD7Y-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>000BKX-E</td>\n",
       "      <td>C5J6CK-S</td>\n",
       "      <td>06/30/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314602</td>\n",
       "      <td>C5J6CK-S-US</td>\n",
       "      <td>20010630</td>\n",
       "      <td>06/30/2001C5J6CK-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>000BKX-E</td>\n",
       "      <td>C5J6CK-S</td>\n",
       "      <td>09/30/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314603</td>\n",
       "      <td>C5J6CK-S-US</td>\n",
       "      <td>20010930</td>\n",
       "      <td>09/30/2001C5J6CK-S-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FACTSET_ENTITY_ID   FSYM_ID REPORT_DATE  ADJ_MV  REPORTED_HOLDING  \\\n",
       "616           000BJX-E  CSTD7Y-S  03/31/2002     NaN             46400   \n",
       "617           000BJX-E  CSTD7Y-S  06/30/2002     NaN             46400   \n",
       "618           000BJX-E  CSTD7Y-S  09/30/2002     NaN             46400   \n",
       "8054          000BKX-E  C5J6CK-S  06/30/2001     NaN            314602   \n",
       "8055          000BKX-E  C5J6CK-S  09/30/2001     NaN            314603   \n",
       "\n",
       "      New_FSYM_ID date_combo           to_be_joined  \n",
       "616   CSTD7Y-S-US   20020331  03/31/2002CSTD7Y-S-US  \n",
       "617   CSTD7Y-S-US   20020630  06/30/2002CSTD7Y-S-US  \n",
       "618   CSTD7Y-S-US   20020930  09/30/2002CSTD7Y-S-US  \n",
       "8054  C5J6CK-S-US   20010630  06/30/2001C5J6CK-S-US  \n",
       "8055  C5J6CK-S-US   20010930  09/30/2001C5J6CK-S-US  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.loc[null_index][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we spend further time on this, first question: how many New_FSYM ID's have this null problem?\n",
    "\n",
    "fund13f_null = fund13f.loc[null_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7451"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fund13f_null['New_FSYM_ID'].unique())\n",
    "\n",
    "# So, its a big problem. More than 10% of funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000000\n",
      "45143\n"
     ]
    }
   ],
   "source": [
    "print(len(fund13f))\n",
    "print(len(fund13f_null))\n",
    "\n",
    "# So, on average these problem hedge funds have made an appearance for just 6 - 7 quarters. I say delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f = fund13f.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FACTSET_ENTITY_ID    0\n",
       "FSYM_ID              0\n",
       "REPORT_DATE          0\n",
       "ADJ_MV               0\n",
       "REPORTED_HOLDING     0\n",
       "New_FSYM_ID          0\n",
       "date_combo           0\n",
       "to_be_joined         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f.isnull().sum()\n",
    "\n",
    "# great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_portfolio = fund13f.groupby(['REPORT_DATE','New_FSYM_ID']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ADJ_MV</th>\n",
       "      <th>REPORTED_HOLDING</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPORT_DATE</th>\n",
       "      <th>New_FSYM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">03/31/1999</th>\n",
       "      <th>B00GXG-S-US</th>\n",
       "      <td>65125693.0</td>\n",
       "      <td>4938254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00L3K-S-US</th>\n",
       "      <td>4942009.0</td>\n",
       "      <td>1040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01573-S-US</th>\n",
       "      <td>294315326.0</td>\n",
       "      <td>12901211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01DPB-S-US</th>\n",
       "      <td>106733801.0</td>\n",
       "      <td>3712480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ADJ_MV  REPORTED_HOLDING\n",
       "REPORT_DATE New_FSYM_ID                               \n",
       "03/31/1999  B00GXG-S-US   65125693.0           4938254\n",
       "            B00L3K-S-US    4942009.0           1040423\n",
       "            B01573-S-US  294315326.0          12901211\n",
       "            B01DPB-S-US  106733801.0           3712480"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_portfolio[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_portfolio2 = total_portfolio[['REPORT_DATE','New_FSYM_ID','ADJ_MV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORT_DATE</th>\n",
       "      <th>New_FSYM_ID</th>\n",
       "      <th>ADJ_MV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/31/1999</td>\n",
       "      <td>B00GXG-S-US</td>\n",
       "      <td>65125693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/31/1999</td>\n",
       "      <td>B00L3K-S-US</td>\n",
       "      <td>4942009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/31/1999</td>\n",
       "      <td>B01573-S-US</td>\n",
       "      <td>294315326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/31/1999</td>\n",
       "      <td>B01DPB-S-US</td>\n",
       "      <td>106733801.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REPORT_DATE  New_FSYM_ID       ADJ_MV\n",
       "1  03/31/1999  B00GXG-S-US   65125693.0\n",
       "2  03/31/1999  B00L3K-S-US    4942009.0\n",
       "3  03/31/1999  B01573-S-US  294315326.0\n",
       "4  03/31/1999  B01DPB-S-US  106733801.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_portfolio2[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_portfolio2['to_be_joined_key2'] = total_portfolio2['REPORT_DATE'] + total_portfolio2['New_FSYM_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f['to_be_joined'] = fund13f['REPORT_DATE'] + fund13f['New_FSYM_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f2 = pd.merge(fund13f,\n",
    "                    total_portfolio2,\n",
    "                    left_on='to_be_joined',\n",
    "                    right_on='to_be_joined_key2',\n",
    "                    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACTSET_ENTITY_ID</th>\n",
       "      <th>FSYM_ID</th>\n",
       "      <th>REPORT_DATE_x</th>\n",
       "      <th>ADJ_MV_x</th>\n",
       "      <th>REPORTED_HOLDING</th>\n",
       "      <th>New_FSYM_ID_x</th>\n",
       "      <th>date_combo</th>\n",
       "      <th>to_be_joined</th>\n",
       "      <th>REPORT_DATE_y</th>\n",
       "      <th>New_FSYM_ID_y</th>\n",
       "      <th>ADJ_MV_y</th>\n",
       "      <th>to_be_joined_key2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>12/31/2004</td>\n",
       "      <td>534527.0</td>\n",
       "      <td>13300</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>20041231</td>\n",
       "      <td>12/31/2004B00CQC-S-US</td>\n",
       "      <td>12/31/2004</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>1.004516e+09</td>\n",
       "      <td>12/31/2004B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>03/31/2005</td>\n",
       "      <td>390040.0</td>\n",
       "      <td>9800</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>20050331</td>\n",
       "      <td>03/31/2005B00CQC-S-US</td>\n",
       "      <td>03/31/2005</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>1.039999e+09</td>\n",
       "      <td>03/31/2005B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>06/30/2005</td>\n",
       "      <td>390299.0</td>\n",
       "      <td>9100</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>20050630</td>\n",
       "      <td>06/30/2005B00CQC-S-US</td>\n",
       "      <td>06/30/2005</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>1.094276e+09</td>\n",
       "      <td>06/30/2005B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>09/30/2005</td>\n",
       "      <td>417417.0</td>\n",
       "      <td>9100</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>20050930</td>\n",
       "      <td>09/30/2005B00CQC-S-US</td>\n",
       "      <td>09/30/2005</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>1.242329e+09</td>\n",
       "      <td>09/30/2005B00CQC-S-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000BJX-E</td>\n",
       "      <td>B00CQC-S</td>\n",
       "      <td>12/31/2005</td>\n",
       "      <td>188225.0</td>\n",
       "      <td>4350</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>20051231</td>\n",
       "      <td>12/31/2005B00CQC-S-US</td>\n",
       "      <td>12/31/2005</td>\n",
       "      <td>B00CQC-S-US</td>\n",
       "      <td>1.029819e+09</td>\n",
       "      <td>12/31/2005B00CQC-S-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FACTSET_ENTITY_ID   FSYM_ID REPORT_DATE_x  ADJ_MV_x  REPORTED_HOLDING  \\\n",
       "0          000BJX-E  B00CQC-S    12/31/2004  534527.0             13300   \n",
       "1          000BJX-E  B00CQC-S    03/31/2005  390040.0              9800   \n",
       "2          000BJX-E  B00CQC-S    06/30/2005  390299.0              9100   \n",
       "3          000BJX-E  B00CQC-S    09/30/2005  417417.0              9100   \n",
       "4          000BJX-E  B00CQC-S    12/31/2005  188225.0              4350   \n",
       "\n",
       "  New_FSYM_ID_x date_combo           to_be_joined REPORT_DATE_y New_FSYM_ID_y  \\\n",
       "0   B00CQC-S-US   20041231  12/31/2004B00CQC-S-US    12/31/2004   B00CQC-S-US   \n",
       "1   B00CQC-S-US   20050331  03/31/2005B00CQC-S-US    03/31/2005   B00CQC-S-US   \n",
       "2   B00CQC-S-US   20050630  06/30/2005B00CQC-S-US    06/30/2005   B00CQC-S-US   \n",
       "3   B00CQC-S-US   20050930  09/30/2005B00CQC-S-US    09/30/2005   B00CQC-S-US   \n",
       "4   B00CQC-S-US   20051231  12/31/2005B00CQC-S-US    12/31/2005   B00CQC-S-US   \n",
       "\n",
       "       ADJ_MV_y      to_be_joined_key2  \n",
       "0  1.004516e+09  12/31/2004B00CQC-S-US  \n",
       "1  1.039999e+09  03/31/2005B00CQC-S-US  \n",
       "2  1.094276e+09  06/30/2005B00CQC-S-US  \n",
       "3  1.242329e+09  09/30/2005B00CQC-S-US  \n",
       "4  1.029819e+09  12/31/2005B00CQC-S-US  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f2['date_combo'] = fund13f2['REPORT_DATE_x'].astype(str)\n",
    "fund13f2['date_combo'] = fund13f2.REPORT_DATE_x.str[6:10] + fund13f2.REPORT_DATE_x.str[0:2] + fund13f2.REPORT_DATE_x.str[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20050331\n",
       "2    20050630\n",
       "3    20050930\n",
       "4    20051231\n",
       "Name: date_combo, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f2['date_combo'][1:5]\n",
    "\n",
    "# date_combo is going to be the ultimate column that we are going to use to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FACTSET_ENTITY_ID', 'FSYM_ID', 'REPORT_DATE_x', 'ADJ_MV_x',\n",
       "       'REPORTED_HOLDING', 'New_FSYM_ID_x', 'date_combo', 'to_be_joined',\n",
       "       'REPORT_DATE_y', 'New_FSYM_ID_y', 'ADJ_MV_y', 'to_be_joined_key2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund13f2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-a2c517d0311c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfund13f2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfund13f2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ADJ_MV_y\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Portfolio_value\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, index, columns, **kwargs)\u001b[0m\n\u001b[0;32m   2744\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2745\u001b[0m         return super(DataFrame, self).rename(index=index, columns=columns,\n\u001b[1;32m-> 2746\u001b[1;33m                                              **kwargs)\n\u001b[0m\u001b[0;32m   2747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2748\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fillna'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             result._data = result._data.rename_axis(f, axis=baxis, copy=copy,\n\u001b[1;32m--> 727\u001b[1;33m                                                     level=level)\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mrename_axis\u001b[1;34m(self, mapper, axis, copy, level)\u001b[0m\n\u001b[0;32m   2851\u001b[0m         \"\"\"\n\u001b[0;32m   2852\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2853\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_transform_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2854\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_transform_index\u001b[1;34m(index, func, level)\u001b[0m\n\u001b[0;32m   4753\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4754\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4755\u001b[1;33m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4756\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4753\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4754\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4755\u001b[1;33m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4756\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fund13f2 = fund13f2.rename(index=str, columns={\"ADJ_MV_y\": \"Portfolio_value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f2['Percentage_of_fund'] = fund13f2['ADJ_MV_x']/fund13f2['Portfolio_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f2 = fund13f2[['date_combo', 'FACTSET_ENTITY_ID', 'New_FSYM_ID_x', '']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    G0Z82X-S-US\n",
       "1    G0Z82X-S-US\n",
       "2    G0Z82X-S-US\n",
       "3    G0Z82X-S-US\n",
       "Name: FS_PERM_SEC_ID, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_institutions_pricevolume['FS_PERM_SEC_ID'][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund13f3 = pd.merge(fund13f2,\n",
    "                    financials_institutions_pricevolume['RET'],\n",
    "                    left_on = 'to_be_joined',\n",
    "                    right_on = 'RET',\n",
    "                    how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
